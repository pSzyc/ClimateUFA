{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from classify import data_pipeline, eco_selector\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validator(df):\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    if df.duplicated().any():\n",
        "        print(\"Found duplicated rows\")\n",
        "        df = df.drop_duplicates()\n",
        "    if df.text.isna().any():\n",
        "        print(\"Found NaN values in text column\")\n",
        "        df = df.dropna(subset=['text'])\n",
        "    if 'vectorized' in df.columns.values:\n",
        "        print(\"Found vectorized column\")\n",
        "        df = df.drop(columns=['vectorized'])\n",
        "    if df.index.duplicated().any():\n",
        "        print(\"Duplicated index!!!\")\n",
        "        df = df.reset_index()\n",
        "        df = df.drop(columns = ['id'])\n",
        "        df = df.rename(columns = {'index': 'id'})\n",
        "    elif 'id' not in df.reset_index().columns.values:\n",
        "        print(\"No id column found\")\n",
        "        df = df.reset_index()\n",
        "        df = df.rename(columns = {'index': 'id'})\n",
        "    if df.date.isna().any():\n",
        "        print(\"Found NaN values in date column\")\n",
        "        df = df.dropna(subset=['date'])\n",
        "    df = df[df['date'] < datetime(2023, 1, 1)]\n",
        "    print(f\"Found {len(df)} files\")\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Big corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rzepa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "rzepa\n",
            "Configuration finished\n"
          ]
        }
      ],
      "source": [
        "corp = 'rzepa'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_final = pd.concat([df_eco, eco_selector(df_rest, main = True)])\n",
        "df_final = validator(df_final)\n",
        "df_final.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wyborcza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wyborcza\n",
            "Configuration finished\n",
            "Dataset of 10248 samples\n",
            "label\n",
            "1    5124\n",
            "0    5124\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9980487804878049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 130/130 [03:08<00:00,  1.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55153 1117\n",
            "Found vectorized column\n",
            "Duplicated index!!!\n",
            "Found 6241 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'wyborcza'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_final = pd.concat([df_eco, eco_selector(df_rest, main = True)])\n",
        "df_final = validator(df_final)\n",
        "df_final.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gazeta Polska Codziennie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "gpc\n",
            "Configuration finished\n",
            "Dataset of 14640 samples\n",
            "label\n",
            "0    7454\n",
            "1    7186\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9986338797814208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [01:06<00:00,  2.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10645 1788\n",
            "Found duplicated rows\n",
            "Found vectorized column\n",
            "Duplicated index!!!\n",
            "Found 3874 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'gpc'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest, False)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polityka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "polityka\n",
            "Configuration finished\n",
            "Dataset of 8508 samples\n",
            "label\n",
            "1    4338\n",
            "0    4170\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9917743830787309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:47<00:00,  7.89s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2162 281\n",
            "Found vectorized column\n",
            "Found 950 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'polityka'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Small Corpuses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dorzeczy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "dorzeczy\n",
            "Configuration finished\n",
            "Dataset of 7186 samples\n",
            "label\n",
            "0    3620\n",
            "1    3566\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9944367176634215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:13<00:00,  4.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1032 100\n",
            "Found vectorized column\n",
            "Found 309 files\n"
          ]
        }
      ],
      "source": [
        "\n",
        "corp = 'dorzeczy'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wprost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wprost\n",
            "Configuration finished\n",
            "Dataset of 7454 samples\n",
            "label\n",
            "1    3850\n",
            "0    3604\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9932975871313673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:09<00:00,  3.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "857 113\n",
            "Found vectorized column\n",
            "Found 538 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'wprost'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Newsweek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "newsweek\n",
            "Configuration finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset of 8340 samples\n",
            "label\n",
            "0    4408\n",
            "1    3932\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9940047961630696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:38<00:00,  6.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2109 179\n",
            "Found vectorized column\n",
            "Found 645 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'newsweek'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## wPolityce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'rzepa', 2: 'gpc', 3: 'newsweek', 4: 'wprost', 5: 'dorzeczy', 6: 'polityka', 7: 'wyborcza', 8: 'wpolityce'}\n",
            "wpolityce\n",
            "Configuration finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset of 7666 samples\n",
            "label\n",
            "0    3882\n",
            "1    3784\n",
            "Name: count, dtype: int64\n",
            "Preprocessing ended\n",
            "Accuracy of model 0.9921773142112125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:49<00:00, 12.41s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1536 145\n",
            "Found vectorized column\n",
            "Found 470 files\n"
          ]
        }
      ],
      "source": [
        "corp = 'wpolityce'\n",
        "df_rest, df_eco = data_pipeline(corp)\n",
        "df_eco = pd.concat([df_eco, eco_selector(df_rest)])\n",
        "df_eco = validator(df_eco)\n",
        "df_eco.to_csv(f\"eco_{corp}.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
