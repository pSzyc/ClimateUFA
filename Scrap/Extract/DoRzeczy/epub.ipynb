{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ebooklib\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "\n",
    "blacklist = [   '[document]',   'noscript', 'header',   'html', 'meta', 'head','input', 'script',   ]\n",
    "\n",
    "def epub2thtml(epub_path):\n",
    "    book = epub.read_epub(epub_path)\n",
    "    chapters = []\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            chapters.append(item.get_content())\n",
    "    return chapters\n",
    "\n",
    "def chap2text(chap):\n",
    "    output = ''\n",
    "    soup = BeautifulSoup(chap, 'html.parser')\n",
    "    text = soup.find_all(text=True)\n",
    "    for t in text:\n",
    "        if t.parent.name not in blacklist:\n",
    "            output += '{} '.format(t)\n",
    "    return output\n",
    "\n",
    "def thtml2ttext(thtml):\n",
    "    Output = []\n",
    "    for html in thtml:\n",
    "        text =  chap2text(html)\n",
    "        Output.append(text)\n",
    "    return Output\n",
    "\n",
    "def epub2text(epub_path):\n",
    "    chapters = epub2thtml(epub_path)\n",
    "    ttext = thtml2ttext(chapters)\n",
    "    return ttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_getter(i):\n",
    "    index =  405 + i \n",
    "    return f\"https://tygodnik.dorzeczy.pl/archiwum/{index}/dorzeczy-{i}-{2021}.html\"\n",
    "\n",
    "def titles_extractor(titles_raw):\n",
    "    print( re.findall(\"(?<=\\n\\s)\\d+(?=\\.\\s\\s)\",titles_raw)[-1], end=' ')\n",
    "    titles = re.split(\"\\n\\s\\d+\\.\\s\\s\", titles_raw)[1:]\n",
    "    titles =[ title.strip() for title in titles ]\n",
    "    return titles\n",
    "\n",
    "def pipeline(file):\n",
    "    put = epub2text(file)\n",
    "    titles = titles_extractor(put[1])\n",
    "    articles = put[2:]\n",
    "    print(len(titles))\n",
    "    if len(titles) != len(articles): print(file)\n",
    "    return pd.DataFrame(list(zip(titles, articles)), columns=['title', 'article'])\n",
    "\n",
    "def author_extractor(article):\n",
    "    title = article['title']\n",
    "    txt = article['article']\n",
    "    txt = txt.replace('\\xa0', ' ')\n",
    "    title = title.replace(\"*\", \"\\*\")\n",
    "    regex = \"(?<=\\\\n \" + title + \" \\\\n \\\\n )[\\w \\.,]+(?= \\\\n \\\\n)\"\n",
    "    try:\n",
    "        matched = re.search(regex, txt)\n",
    "    except:\n",
    "        print(title)\n",
    "        matched = None\n",
    "    \n",
    "    if matched != None:\n",
    "        return matched[0]\n",
    "    else:\n",
    "        return matched\n",
    "    \n",
    "def text_preprocessor(article):\n",
    "    try:\n",
    "        text =  re.split(\" \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n\", article)[1]\n",
    "    except:\n",
    "        print(article)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in range(6, 50):\n",
    "    df = pipeline(f\"Epubs/dorzeczy-{i}-2021-.epub\")\n",
    "    df['author'] = df.apply(lambda x: author_extractor(x), axis=1)\n",
    "    df['text'] = df['article'].apply(lambda x: text_preprocessor(x))\n",
    "    df['magazine_nr'] = 405 + i\n",
    "    df['link'] = link_getter(i)\n",
    "    df_list.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(df_list)\n",
    "df_all['year'] = 2021\n",
    "df_all.drop(columns=['article'], inplace=True)\n",
    "df_all.to_csv(\"from_epub.csv\")\n",
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
