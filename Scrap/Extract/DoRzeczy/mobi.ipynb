{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mobi\n",
    "import html2text\n",
    "import regex as re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_getter(i):\n",
    "    values = {}\n",
    "    if i in range(411,457):\n",
    "        values['index'] = i-411 + 6\n",
    "        values['year'] = 2021\n",
    "    elif i in range(457,508):\n",
    "        values['index'] = i-457 + 1\n",
    "        values['year'] = 2022\n",
    "    else:\n",
    "        values['index'] = i-508 + 1\n",
    "        values['year'] = 2023\n",
    "\n",
    "    if i > 524:\n",
    "        values['index']-=1    #trick\n",
    "\n",
    "    return f\"https://tygodnik.dorzeczy.pl/archiwum/{i}/dorzeczy-{values['index']}-{values['year']}.html\"\n",
    "\n",
    "link_getter(456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_title(title):\n",
    "    title = re.sub(r'\\?', r'\\?', title)\n",
    "    title = re.sub(r'\\.', r'\\.', title)\n",
    "    title = re.sub(r'\\(', r'\\(', title)\n",
    "    title = re.sub(r'\\)', r'\\)', title)\n",
    "    title = re.sub(r'\\+', r'\\+', title)\n",
    "    title = re.sub(r'\\n', r' ', title)\n",
    "\n",
    "    return title\n",
    "\n",
    "def author_extract(text):\n",
    "    match = re.search(\"(?<=\\\\n\\\\n).+(?=\\s*!\\[\\])\", text)\n",
    "    if match != None:\n",
    "        match = match[0].strip()\n",
    "    return match\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    text = re.sub(r\"[^\\*]+\", '',text, count = 1)\n",
    "    text = text.replace('*', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(txt):\n",
    "\n",
    "    table_of_contents = re.split( \"\\*\\*Table of Contents\\*\\*\",txt)[1]\n",
    "    print(re.findall(\"\\d+(?=\\\\\\.\\s)\", table_of_contents)[-1], end=\" \")\n",
    "    titles = re.split(\"\\n\\n\\d+\\\\\\.\\s\", table_of_contents)[1:]\n",
    "    titles[-1] = titles[-1].strip()\n",
    "    articles = []\n",
    "    for i in range(len(titles)-1):\n",
    "        title_1 = prepare_title(titles[i])\n",
    "        title_2 = prepare_title(titles[i+1])\n",
    "        \n",
    "        if(len(title_1)>50):\n",
    "            split = re.split('\\*\\*'+title_1[:50]+'[^\\*]+\\*\\*', txt)\n",
    "        else:\n",
    "            split = re.split('\\*\\*'+title_1+'\\*\\*', txt)\n",
    "        \n",
    "        txt_1 = \" \".join(split[1:])\n",
    "\n",
    "        if(len(title_2)>50):\n",
    "            split = re.split('\\*\\*'+title_2[:50]+'[^\\*]+\\*\\*', txt_1)\n",
    "        else:\n",
    "            split = re.split('\\*\\*'+ title_2 + '\\*\\*', txt_1)\n",
    "    \n",
    "        articles.append((split[0], titles[i]))\n",
    " \n",
    "\n",
    "    title_last = prepare_title(titles[-1])\n",
    "    \n",
    "    if(len(title_last)>50):\n",
    "        split = re.split('\\*\\*'+title_last[:50]+'[^\\*]+\\*\\*', txt)\n",
    "    else:\n",
    "        split = re.split('\\*\\*'+title_last+'\\*\\*', txt)\n",
    "    \n",
    "    if len(split)!=2: print(title_last + \" ??? \", end=\"\")\n",
    "    txt_1 = split[1]\n",
    "    \n",
    "    splits = ['Na łamach .*Do Rzeczy.* również:','\\*\\*Table of Contents\\*\\*']\n",
    "    for split in splits:\n",
    "        txt_splited = re.split(split, txt_1)\n",
    "        if len(txt_splited) == 2:\n",
    "            articles.append((txt_splited[0], titles[-1]))\n",
    "            break\n",
    "\n",
    "    print(len(articles))\n",
    "    df = pd.DataFrame(articles, columns=[\"article_raw\", \"title\"])\n",
    "    df['author'] = df['article_raw'].apply(author_extract)\n",
    "    df['text'] = df['article_raw'].apply(text_preprocessing)\n",
    "    return df[['text','author','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_list = []\n",
    "#for i in range(459,479):\n",
    "#    filename = f\"Mobi2022/{i}.mobi\"\n",
    "#    print(filename, end=\"\\t\")\n",
    "#    try:\n",
    "#        tempdir, filepath = mobi.extract(filename)\n",
    "#    except:\n",
    "#        print(\"File not found\")\n",
    "#        continue\n",
    "#    file = open(filepath, \"r\")\n",
    "#\n",
    "#    content=file.read()\n",
    "#    txt = html2text.html2text(content)\n",
    "#        \n",
    "#    df = pipeline(txt)\n",
    "#    df['magazine_nr'] = i\n",
    "#    df['year'] = 2022\n",
    "#    df['link'] = link_getter(i)\n",
    "#    df_list.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_22 = pd.concat(df_list)\n",
    "#len(df_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_list = []\n",
    "#for i in range(455,457):\n",
    "#    filename = f\"Mobi2021/{i}.mobi\"\n",
    "#    print(filename, end=\"\\t\")     \n",
    "#\n",
    "#    if i == 437:\n",
    "#        with open(str(i)+\".txt\",'r') as f:\n",
    "#            txt = f.read()\n",
    "#\n",
    "#            df_list.append(pipeline(txt))\n",
    "#            continue\n",
    "#    try:\n",
    "#        tempdir, filepath = mobi.extract(filename)\n",
    "#    except:\n",
    "#        print(\"Doesnt exist\")\n",
    "#        continue\n",
    "#    file = open(filepath, \"r\")\n",
    "#\n",
    "#    try:\n",
    "#        content=file.read()\n",
    "#        txt = html2text.html2text(content)\n",
    "#        \n",
    "#    except UnicodeDecodeError:\n",
    "#        print(\"Unable to read\")\n",
    "#        continue\n",
    "#        \n",
    "#    df = pipeline(txt)\n",
    "#    df['magazine_nr'] = i\n",
    "#    df['year'] = 2021\n",
    "#    df['link'] = link_getter(i)\n",
    "#    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_21 = pd.concat(df_list)\n",
    "#len(df_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "df_list = []\n",
    "files = []\n",
    "for (dirpath, dirnames, filenames) in walk(\"Mobi2023\"):\n",
    "    files.extend(filenames)\n",
    "    \n",
    "num = 508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in files:\n",
    "\n",
    "    print(filename +\" \"+ str(num), end=\"\\t\")  \n",
    "\n",
    "    if(filename ==\"dorzeczy-24-2023-.mobi\"):\n",
    "\n",
    "        filename = filename.replace(\"mobi\", \"txt\")\n",
    "        with open(filename, \"r\")  as file:\n",
    "            txt = file.read()\n",
    "\n",
    "    else:\n",
    "\n",
    "        tempdir, filepath = mobi.extract(\"Mobi2023/\" + filename)\n",
    "\n",
    "        file = open(filepath, \"r\")\n",
    "\n",
    "        try:\n",
    "            content=file.read()\n",
    "            txt = html2text.html2text(content)\n",
    "            with open(\"mobi.txt\", \"w\") as f:\n",
    "                f.write(txt)\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Unable to read\")\n",
    "            continue\n",
    "    \n",
    "    df = pipeline(txt)\n",
    "    if (num == 527): num+=1\n",
    "    df['magazine_nr'] = num\n",
    "    df['link'] = link_getter(num)\n",
    "    df['year'] = 2023\n",
    "    df_list.append(df)\n",
    "    num += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_23 = pd.concat(df_list)\n",
    "len(df_23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"from_mobi.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
